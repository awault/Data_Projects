{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter\n",
    "\n",
    "Create a Spam filter that classifies messages based on the word content.\n",
    "\n",
    "Use a training dataset to estimate the probabilities for new messages.\n",
    "\n",
    "Classify messages based on probability values.\n",
    "\n",
    "Goal is to create a Spam filter that classifies new messages with an accuracy greater than 0%.\n",
    "\n",
    "Dataset was obtained from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/) and is available at the following [link](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n",
    "\n",
    "- Spam: refers to unsolicited or unwanted messages, which often contain advertising or malicious content\n",
    "\n",
    "- Ham: refers to legitimate messages that are not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset\n",
    "\n",
    "The data is tab separated and does not contain a header row. \n",
    "\n",
    "Columns should be named 'Label' and 'Message', respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "file_path = '../../../github/Data/SMSSpamCollection'\n",
    "\n",
    "sms_spam = pd.read_csv(file_path, sep='\\t', header=None, names=['Label', 'Message'])\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset\n",
    "\n",
    "The dataset contains 2 columns and 5,572 records.\n",
    "\n",
    "Approximately 87% of the messages in the dataset are classified as ham, the remaining 13% are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Label    5572 non-null   object\n",
      " 1   Message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sms_spam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     86.59\n",
       "spam    13.41\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review Percentage of Spam Messages in Dataset\n",
    "\n",
    "(sms_spam['Label'].value_counts(normalize=True)*100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Dataset\n",
    "\n",
    "Randomly select 80% of the dataset for training purposes. The remaining 20% will be used to test the efficacy of our Spam filter.\n",
    "\n",
    "The training set and test set should each contain a similar proportion of Spam messages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains 4458 messages.\n",
      "\n",
      "The test set contains 1114 messages.\n"
     ]
    }
   ],
   "source": [
    "# Divide the Dataset Randomly for Training Purposes\n",
    "\n",
    "# Randomly Shuffle the Dataset\n",
    "random_sms_spam = sms_spam.sample(frac=1, random_state=1)              \n",
    "\n",
    "# Calculate the Index to Split the Dataframe 80/20\n",
    "split_index = round(len(random_sms_spam)*0.8)\n",
    "training_set = random_sms_spam[:split_index].reset_index(drop=True)\n",
    "test_set = random_sms_spam[split_index:].reset_index(drop=True)\n",
    "\n",
    "print(f'The training set contains {len(training_set)} messages.')\n",
    "print()\n",
    "print(f'The test set contains {len(test_set)} messages.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       training_set  test_set\n",
      "Label                        \n",
      "ham           86.54      86.8\n",
      "spam          13.46      13.2\n"
     ]
    }
   ],
   "source": [
    "# Is the spam distributed evenly between the Test Set and Training Set\n",
    "\n",
    "training_set_values = (training_set['Label'].value_counts(normalize=True)*100).round(2)\n",
    "test_set_values = (test_set['Label'].value_counts(normalize=True)*100).round(2)\n",
    "proportion_spam = pd.concat({'training_set': training_set_values, 'test_set': test_set_values},axis=1)\n",
    "\n",
    "print(proportion_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "\n",
    "Clean and Transform...\n",
    "\n",
    "Clean training data, remove punctuation and set all text to lowercase.\n",
    "\n",
    "Transform messages into a list of substrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation (Non-alphanumberic characters)\n",
    "# Change All Text to Lower Case\n",
    "# Transform Each Message into a List of Substrings\n",
    "\n",
    "def clean_msg(text):\n",
    "    clean_text = text.str.replace('\\W',' ',regex=True)\n",
    "    clean_text = clean_text.str.lower()\n",
    "    clean_text = clean_text.str.split()\n",
    "    return clean_text\n",
    "\n",
    "training_set['Message'] = clean_msg(training_set['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, Ã¼, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, Ã¼, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dancing', '100txt', 'sexy', 'flying', 'barkleys']\n",
      "\n",
      "There are 7783 words in the vocabulary of the training set.\n"
     ]
    }
   ],
   "source": [
    "# Capture a List of Unique Vocabulary from the Training Dataset\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for sms in training_set['Message']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(vocabulary[:5])\n",
    "print()\n",
    "\n",
    "# Calculate Vocabulary Count as n_vocab\n",
    "\n",
    "n_vocab = len(vocabulary)\n",
    "print(f'There are {n_vocab} words in the vocabulary of the training set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A Word Count Dictionary\n",
    "\n",
    "# Initialize a Dictionary and Populate with Zeros\n",
    "word_count_dict = {}\n",
    "for unique_word in vocabulary:\n",
    "    word_count_dict[unique_word] = [0] * len(training_set['Message'])\n",
    "\n",
    "# Iterate Over Each Message in the Training Set\n",
    "for index, sms in enumerate(training_set['Message']):\n",
    "    # Iterate Over Each Word, Increment the Dictionary Count for Each Occurrence at the Corresponding Index\n",
    "    for word in sms:\n",
    "        word_count_dict[word][index] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>dancing</th>\n",
       "      <th>100txt</th>\n",
       "      <th>sexy</th>\n",
       "      <th>flying</th>\n",
       "      <th>barkleys</th>\n",
       "      <th>astoundingly</th>\n",
       "      <th>insects</th>\n",
       "      <th>finance</th>\n",
       "      <th>...</th>\n",
       "      <th>eat</th>\n",
       "      <th>09061743386</th>\n",
       "      <th>drms</th>\n",
       "      <th>crap</th>\n",
       "      <th>sozi</th>\n",
       "      <th>uks</th>\n",
       "      <th>western</th>\n",
       "      <th>ihave</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, Ã¼, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  dancing  100txt  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0       0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0       0   \n",
       "2   ham                    [welp, apparently, he, retired]        0       0   \n",
       "3   ham                                           [havent]        0       0   \n",
       "4   ham  [i, forgot, 2, ask, Ã¼, all, smth, there, s, a,...        0       0   \n",
       "\n",
       "   sexy  flying  barkleys  astoundingly  insects  finance  ...  eat  \\\n",
       "0     0       0         0             0        0        0  ...    0   \n",
       "1     0       0         0             0        0        0  ...    0   \n",
       "2     0       0         0             0        0        0  ...    0   \n",
       "3     0       0         0             0        0        0  ...    0   \n",
       "4     0       0         0             0        0        0  ...    0   \n",
       "\n",
       "   09061743386  drms  crap  sozi  uks  western  ihave  chocolate  away  \n",
       "0            0     0     0     0    0        0      0          0     0  \n",
       "1            0     0     0     0    0        0      0          0     0  \n",
       "2            0     0     0     0    0        0      0          0     0  \n",
       "3            0     0     0     0    0        0      0          0     0  \n",
       "4            0     0     0     0    0        0      0          0     0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the Dictionary to a DataFrame \n",
    "\n",
    "word_counts = pd.DataFrame(word_count_dict)\n",
    "\n",
    "# Join the Dataframe with the Training Set on the Horizontal Axis\n",
    "\n",
    "clean_training_set = training_set.merge(word_counts,left_index=True,right_index=True)\n",
    "clean_training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Probability with Naive Bayes\n",
    "\n",
    "We will classify messages based on probabilities calculated with the Naive Bayes algorithm. The probability each message is either spam or ham is calculated.\n",
    "\n",
    "$\n",
    "P(Spam | w_1, w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\prod\\nolimits_{i=1}^{n} P(x_i | C_k)\n",
    "$\n",
    "\n",
    "*The symbol â means \"directly proportional too\"*\n",
    "\n",
    "*The symbol $\\prod$ represents the product of the probabilities for each feature $x_i$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment Training Set by Labels (Spam or Ham)\n",
    "\n",
    "spam_msg = clean_training_set[clean_training_set['Label']== 'spam']\n",
    "ham_msg = clean_training_set[clean_training_set['Label']== 'ham']\n",
    "\n",
    "# Calculate P(Spam) and P(Ham)\n",
    "\n",
    "p_of_spam = len(spam_msg) / len(clean_training_set)\n",
    "p_of_ham = len(ham_msg) / len(clean_training_set)\n",
    "\n",
    "# N_Spam\n",
    "\n",
    "n_words_per_spam_msg = spam_msg['Message'].apply(len)\n",
    "n_spam = n_words_per_spam_msg.sum()\n",
    "\n",
    "# N_Ham\n",
    "\n",
    "n_words_per_ham_msg = ham_msg['Message'].apply(len)\n",
    "n_ham = n_words_per_ham_msg.sum()\n",
    "\n",
    "alpha = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Parameters P(Wi|Spam) and P(Wi|Ham)\n",
    "# Each parameter is the conditional probability value associated with each word in the vocabulary.\n",
    "\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_msg[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam+alpha)/(n_spam+alpha+n_vocab)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham_msg[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham+alpha)/(n_ham+alpha+n_vocab)\n",
    "    parameters_ham[word] = p_word_given_ham\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Function to Classify Messages with Naive Bayes\n",
    "\n",
    "def classify(message):\n",
    "    # message: a string\n",
    "\n",
    "    # Clean and Format Message\n",
    "    message = re.sub('\\W',' ',message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    # Set Initial Probabilities for Spam and Ham\n",
    "    p_spam_given_message = p_of_spam\n",
    "    p_ham_given_message = p_of_ham\n",
    "\n",
    "    # Calculate Conditional Probabilities for Each Word\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    # Print Probabilities\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    # Classify the message as Spam or Ham based on the probabilities\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3476009873135234e-25\n",
      "P(Ham|message): 1.9365368329766623e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "# Spam Test Message\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4364950561289247e-25\n",
      "P(Ham|message): 3.687133462921691e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "# Ham Test Message\n",
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    # message: a string\n",
    "\n",
    "    # Clean and Format Message\n",
    "    message = re.sub('\\W',' ',message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    # Set Initial Probabilities for Spam and Ham\n",
    "    p_spam_given_message = p_of_spam\n",
    "    p_ham_given_message = p_of_ham\n",
    "\n",
    "    # Calculate Conditional Probabilities for Each Word\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    # Classify the message as Spam or Ham based on the probabilities\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'equal probability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message Prediction\n",
       "0   ham          Later i guess. I needa do mcat study too.        ham\n",
       "1   ham             But i haf enuff space got like 4 mb...        ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...       spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...        ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...        ham"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Prediction'] = test_set['Message'].apply(classify_test_set)\n",
    "test_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "\n",
      "Incorrect: 14\n",
      "\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "total = test_set.shape[0]\n",
    "correct = 0\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['Prediction']:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Correct:', correct)\n",
    "print()\n",
    "print(f'Incorrect:', total-correct)\n",
    "print()\n",
    "print(f'Accuracy:', correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "update_feb_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
